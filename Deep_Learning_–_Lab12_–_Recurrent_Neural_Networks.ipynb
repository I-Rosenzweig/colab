{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNnOcqjw5HVrJhjh4VYlUT7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/I-Rosenzweig/colab/blob/main/Deep_Learning_%E2%80%93_Lab12_%E2%80%93_Recurrent_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJ8HIAy7w6z3",
        "outputId": "028c4b2b-1b9e-4c20-df70-5383b450f909"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HH_tvc2w6LR",
        "outputId": "a26e0e56-86ce-4984-aa49-7a81335fe7fa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jfs5UgPzwN-Y",
        "outputId": "17505fc3-619a-47d0-b927-f6a598b01e50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n",
            "x_train shape: (25000, 100)\n",
            "x_test shape: (25000, 100)\n",
            "Build model...\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_15 (Embedding)    (None, None, 128)         1280000   \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,411,713\n",
            "Trainable params: 1,411,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.utils import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.datasets import imdb\n",
        "max_features = 10000\n",
        "maxlen = 100 # cut texts after this number of words (among top max_features most common words)\n",
        "batch_size = 32\n",
        "NOH = [64,128,256,384]\n",
        "EOD = [32,64,128,256]\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy',\n",
        " optimizer='adam',\n",
        " metrics=['accuracy'])\n",
        "print('Train...')\n",
        "model.fit(x_train, y_train,batch_size=batch_size,epochs=10,validation_split=0.05)\n",
        "score, acc = model.evaluate(x_test, y_test,batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(tf.keras.layers.SimpleRNN(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeQiN6axwl81",
        "outputId": "f91ae6b8-0138-4632-d4a4-6fe274851342"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train...\n",
            "Epoch 1/10\n",
            "743/743 [==============================] - 35s 43ms/step - loss: 0.4167 - accuracy: 0.8065 - val_loss: 0.3932 - val_accuracy: 0.8256\n",
            "Epoch 2/10\n",
            "743/743 [==============================] - 11s 14ms/step - loss: 0.2633 - accuracy: 0.8959 - val_loss: 0.3953 - val_accuracy: 0.8456\n",
            "Epoch 3/10\n",
            "743/743 [==============================] - 9s 12ms/step - loss: 0.1852 - accuracy: 0.9295 - val_loss: 0.5115 - val_accuracy: 0.8256\n",
            "Epoch 4/10\n",
            "743/743 [==============================] - 8s 11ms/step - loss: 0.1281 - accuracy: 0.9525 - val_loss: 0.4475 - val_accuracy: 0.8272\n",
            "Epoch 5/10\n",
            "743/743 [==============================] - 8s 11ms/step - loss: 0.1001 - accuracy: 0.9635 - val_loss: 0.5308 - val_accuracy: 0.8232\n",
            "Epoch 6/10\n",
            "743/743 [==============================] - 7s 10ms/step - loss: 0.0667 - accuracy: 0.9780 - val_loss: 0.7662 - val_accuracy: 0.8192\n",
            "Epoch 7/10\n",
            "743/743 [==============================] - 7s 9ms/step - loss: 0.0549 - accuracy: 0.9824 - val_loss: 0.6931 - val_accuracy: 0.8096\n",
            "Epoch 8/10\n",
            "743/743 [==============================] - 7s 10ms/step - loss: 0.0463 - accuracy: 0.9848 - val_loss: 0.7404 - val_accuracy: 0.8088\n",
            "Epoch 9/10\n",
            "743/743 [==============================] - 8s 10ms/step - loss: 0.0296 - accuracy: 0.9902 - val_loss: 0.8186 - val_accuracy: 0.8152\n",
            "Epoch 10/10\n",
            "743/743 [==============================] - 7s 9ms/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 1.1008 - val_accuracy: 0.8200\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.0265 - accuracy: 0.8273\n",
            "Test score: 1.0264760255813599\n",
            "Test accuracy: 0.8273199796676636\n",
            "Loading data...\n",
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n",
            "x_train shape: (25000, 100)\n",
            "x_test shape: (25000, 100)\n",
            "Build model...\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_16 (Embedding)    (None, None, 128)         1280000   \n",
            "                                                                 \n",
            " simple_rnn_2 (SimpleRNN)    (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,313,025\n",
            "Trainable params: 1,313,025\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "print('Train...')\n",
        "model.fit(x_train, y_train,batch_size=batch_size,epochs=10,validation_split=0.05)\n",
        "score, acc = model.evaluate(x_test, y_test,batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(tf.keras.layers.GRU(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wes9_VIswrQd",
        "outputId": "662ca26b-fcbc-48bc-da7b-d8eae597dd0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train...\n",
            "Epoch 1/10\n",
            "743/743 [==============================] - 112s 149ms/step - loss: 0.7195 - accuracy: 0.5130 - val_loss: 0.6771 - val_accuracy: 0.5456\n",
            "Epoch 2/10\n",
            "743/743 [==============================] - 89s 120ms/step - loss: 0.5910 - accuracy: 0.6771 - val_loss: 0.5580 - val_accuracy: 0.7136\n",
            "Epoch 3/10\n",
            "743/743 [==============================] - 89s 120ms/step - loss: 0.4887 - accuracy: 0.7770 - val_loss: 0.5466 - val_accuracy: 0.7632\n",
            "Epoch 4/10\n",
            "743/743 [==============================] - 86s 116ms/step - loss: 0.4950 - accuracy: 0.7627 - val_loss: 0.5553 - val_accuracy: 0.7344\n",
            "Epoch 5/10\n",
            "743/743 [==============================] - 87s 118ms/step - loss: 0.4055 - accuracy: 0.8270 - val_loss: 0.4875 - val_accuracy: 0.7920\n",
            "Epoch 6/10\n",
            "743/743 [==============================] - 85s 115ms/step - loss: 0.3464 - accuracy: 0.8568 - val_loss: 0.5539 - val_accuracy: 0.7256\n",
            "Epoch 7/10\n",
            " 84/743 [==>...........................] - ETA: 1:17 - loss: 0.2946 - accuracy: 0.8888"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy',\n",
        " optimizer='adam',metrics=['accuracy'])\n",
        "print('Train...')\n",
        "model.fit(x_train, y_train,batch_size=batch_size,epochs=10,validation_split=0.05)\n",
        "score, acc = model.evaluate(x_test, y_test,batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n"
      ],
      "metadata": {
        "id": "K87byjJKwtW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.datasets import imdb\n",
        "max_features = 10000\n",
        "maxlen = 100 # cut texts after this number of words (among top max_features most common words)\n",
        "batch_size = 32\n",
        "NOH = [64,128,256,384]\n",
        "EOD = [32,64,128,256]\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy',\n",
        " optimizer='adam',\n",
        " metrics=['accuracy'])\n",
        "print('Train...')\n",
        "model.fit(x_train, y_train,batch_size=batch_size,epochs=10,validation_split=0.05)\n",
        "score, acc = model.evaluate(x_test, y_test,batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(tf.keras.layers.SimpleRNN(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "print('Train...')\n",
        "model.fit(x_train, y_train,batch_size=batch_size,epochs=10,validation_split=0.05)\n",
        "score, acc = model.evaluate(x_test, y_test,batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(tf.keras.layers.GRU(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy',\n",
        " optimizer='adam',metrics=['accuracy'])\n",
        "print('Train...')\n",
        "model.fit(x_train, y_train,batch_size=batch_size,epochs=10,validation_split=0.05)\n",
        "score, acc = model.evaluate(x_test, y_test,batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RLQLdmfXgh4",
        "outputId": "e7652650-2b7f-45de-e21e-752dad2f72ff"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n",
            "x_train shape: (25000, 100)\n",
            "x_test shape: (25000, 100)\n",
            "Build model...\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_12 (Embedding)    (None, None, 128)         1280000   \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,411,713\n",
            "Trainable params: 1,411,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train...\n",
            "Epoch 1/10\n",
            "743/743 [==============================] - 38s 47ms/step - loss: 0.4253 - accuracy: 0.7980 - val_loss: 0.3592 - val_accuracy: 0.8440\n",
            "Epoch 2/10\n",
            "743/743 [==============================] - 22s 29ms/step - loss: 0.2550 - accuracy: 0.8992 - val_loss: 0.3608 - val_accuracy: 0.8392\n",
            "Epoch 3/10\n",
            "743/743 [==============================] - 15s 20ms/step - loss: 0.1841 - accuracy: 0.9303 - val_loss: 0.4166 - val_accuracy: 0.8408\n",
            "Epoch 4/10\n",
            "743/743 [==============================] - 8s 11ms/step - loss: 0.1277 - accuracy: 0.9545 - val_loss: 0.5657 - val_accuracy: 0.8240\n",
            "Epoch 5/10\n",
            "743/743 [==============================] - 8s 11ms/step - loss: 0.0888 - accuracy: 0.9698 - val_loss: 0.6260 - val_accuracy: 0.8288\n",
            "Epoch 6/10\n",
            "743/743 [==============================] - 6s 8ms/step - loss: 0.0771 - accuracy: 0.9738 - val_loss: 0.6145 - val_accuracy: 0.8240\n",
            "Epoch 7/10\n",
            "743/743 [==============================] - 7s 10ms/step - loss: 0.0484 - accuracy: 0.9844 - val_loss: 0.7428 - val_accuracy: 0.8208\n",
            "Epoch 8/10\n",
            "743/743 [==============================] - 6s 8ms/step - loss: 0.0398 - accuracy: 0.9867 - val_loss: 0.8086 - val_accuracy: 0.8224\n",
            "Epoch 9/10\n",
            "743/743 [==============================] - 7s 10ms/step - loss: 0.0335 - accuracy: 0.9892 - val_loss: 0.7900 - val_accuracy: 0.8288\n",
            "Epoch 10/10\n",
            "743/743 [==============================] - 6s 8ms/step - loss: 0.0305 - accuracy: 0.9909 - val_loss: 0.7627 - val_accuracy: 0.8192\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.7921 - accuracy: 0.8200\n",
            "Test score: 0.7920751571655273\n",
            "Test accuracy: 0.8199599981307983\n",
            "Loading data...\n",
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n",
            "x_train shape: (25000, 100)\n",
            "x_test shape: (25000, 100)\n",
            "Build model...\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_13 (Embedding)    (None, None, 128)         1280000   \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,313,025\n",
            "Trainable params: 1,313,025\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train...\n",
            "Epoch 1/10\n",
            "743/743 [==============================] - 111s 148ms/step - loss: 0.6186 - accuracy: 0.6395 - val_loss: 0.6549 - val_accuracy: 0.5888\n",
            "Epoch 2/10\n",
            "743/743 [==============================] - 87s 118ms/step - loss: 0.5635 - accuracy: 0.6972 - val_loss: 0.5034 - val_accuracy: 0.7720\n",
            "Epoch 3/10\n",
            "743/743 [==============================] - 89s 120ms/step - loss: 0.5457 - accuracy: 0.7165 - val_loss: 0.5908 - val_accuracy: 0.6784\n",
            "Epoch 4/10\n",
            "743/743 [==============================] - 86s 115ms/step - loss: 0.4492 - accuracy: 0.7999 - val_loss: 0.4952 - val_accuracy: 0.7712\n",
            "Epoch 5/10\n",
            "743/743 [==============================] - 86s 116ms/step - loss: 0.3740 - accuracy: 0.8432 - val_loss: 0.4945 - val_accuracy: 0.7904\n",
            "Epoch 6/10\n",
            "743/743 [==============================] - 86s 115ms/step - loss: 0.3264 - accuracy: 0.8718 - val_loss: 0.4959 - val_accuracy: 0.7672\n",
            "Epoch 7/10\n",
            "743/743 [==============================] - 87s 117ms/step - loss: 0.4093 - accuracy: 0.8235 - val_loss: 0.6261 - val_accuracy: 0.6624\n",
            "Epoch 8/10\n",
            "743/743 [==============================] - 87s 117ms/step - loss: 0.4625 - accuracy: 0.7823 - val_loss: 0.4831 - val_accuracy: 0.7960\n",
            "Epoch 9/10\n",
            "743/743 [==============================] - 88s 119ms/step - loss: 0.3039 - accuracy: 0.8816 - val_loss: 0.5025 - val_accuracy: 0.7816\n",
            "Epoch 10/10\n",
            "743/743 [==============================] - 87s 118ms/step - loss: 0.2713 - accuracy: 0.9008 - val_loss: 0.5149 - val_accuracy: 0.8032\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4921 - accuracy: 0.8084\n",
            "Test score: 0.4921327233314514\n",
            "Test accuracy: 0.8083599805831909\n",
            "Loading data...\n",
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n",
            "x_train shape: (25000, 100)\n",
            "x_test shape: (25000, 100)\n",
            "Build model...\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_14 (Embedding)    (None, None, 128)         1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 128)               99072     \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,379,201\n",
            "Trainable params: 1,379,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train...\n",
            "Epoch 1/10\n",
            "743/743 [==============================] - 36s 44ms/step - loss: 0.4290 - accuracy: 0.7947 - val_loss: 0.3799 - val_accuracy: 0.8440\n",
            "Epoch 2/10\n",
            "743/743 [==============================] - 10s 13ms/step - loss: 0.2473 - accuracy: 0.9016 - val_loss: 0.3572 - val_accuracy: 0.8448\n",
            "Epoch 3/10\n",
            "743/743 [==============================] - 8s 11ms/step - loss: 0.1574 - accuracy: 0.9437 - val_loss: 0.4731 - val_accuracy: 0.8368\n",
            "Epoch 4/10\n",
            "743/743 [==============================] - 7s 10ms/step - loss: 0.0989 - accuracy: 0.9660 - val_loss: 0.5146 - val_accuracy: 0.8328\n",
            "Epoch 5/10\n",
            "743/743 [==============================] - 8s 11ms/step - loss: 0.0614 - accuracy: 0.9804 - val_loss: 0.6623 - val_accuracy: 0.8216\n",
            "Epoch 6/10\n",
            "743/743 [==============================] - 7s 9ms/step - loss: 0.0401 - accuracy: 0.9868 - val_loss: 0.7496 - val_accuracy: 0.8136\n",
            "Epoch 7/10\n",
            "743/743 [==============================] - 7s 10ms/step - loss: 0.0290 - accuracy: 0.9901 - val_loss: 0.7976 - val_accuracy: 0.8064\n",
            "Epoch 8/10\n",
            "743/743 [==============================] - 7s 10ms/step - loss: 0.0180 - accuracy: 0.9946 - val_loss: 0.9603 - val_accuracy: 0.8152\n",
            "Epoch 9/10\n",
            "743/743 [==============================] - 7s 9ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.9859 - val_accuracy: 0.8200\n",
            "Epoch 10/10\n",
            "743/743 [==============================] - 7s 10ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 1.0607 - val_accuracy: 0.8232\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.0049 - accuracy: 0.8278\n",
            "Test score: 1.0049158334732056\n",
            "Test accuracy: 0.8277599811553955\n"
          ]
        }
      ]
    }
  ]
}